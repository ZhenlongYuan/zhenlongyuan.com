---
permalink: /
title: ""
excerpt: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

<span class='anchor' id='about-me'></span>

# 👋 About Me 
I'm currently a research intern in AMAP <img src='./images/AMAP.png' style="width: 1.8em;">, Alibaba <img src='./images/Alibaba.png' style="width: 1.7em;">, working with [Xiangxiang Chu](https://cxxgtxy.github.io/). I am fortunate to deeply collaborate with [Shuo Li](https://scholar.google.com/citations?user=6WNtJa0AAAAJ&hl=en), [Yujun Cai](https://vanoracai.github.io/), and [Yiwei Wang](https://wangywust.github.io/), and more broadly with [Manling Li](https://limanling.github.io/), [Zhengzhong Tu](https://vztu.github.io/) and [LiangLin](http://www.linliang.net/). 
Truly grateful for their guidance throughout my academic journey.

My research interest includes Vision-Language Model (VLM), Large Language Model (LLM), Embodied Agents, Multimodal AI, and 3D Vision. I have published 18+ papers <img src="https://img.shields.io/badge/citations-134-red?logo=googlescholar" alt="citations"> at the top international AI conferences such as NeurIPS, ICLR, ICCV, AAAI.

I will be graduating with my Ph.D. in June 2026 and am <span style="color:red">**now exploring PostDoc opportunities for Fall 2026**</span>. If you are interested in my profile, feel free to contact with me via email (📧 yuanzhenlong21b[at]ict[dot]ac[dot]cn) or WeChat (📧 YZL20000224).

# 📚 Research Interests
- ***Foundation Models & Pre-training 🔥🔥***
  - Vision-Language Models (VLMs) / Vision-Language Action (VLA) / Spatial Intelligence
- ***Model Enhancement & Post-training 🔥🔥***
  - Reasoning & Alignment / Tool-Augmented RL / NLP-Enhanced Training
- ***Model Interpretation 🔥🔥***
  - Mechanistic Interpretability / Factuality, Truthfulness, and Social Good
- ***Real-World Applications🔥🔥***
  - Embodied Agents / AI for Science / Biomedical Engineering


# 🔥 Main News

- *2025.10*: &nbsp;🎉🎉 We propose [Video-STAR](https://arxiv.org/abs/2510.08480), which is now available on ArXiv!
- *2025.08*: &nbsp;🎉🎉 Our work [AutoDrive-R²](https://arxiv.org/abs/2509.01944v1) was reported by [AutoDrive Heart (自动驾驶之心)](https://mp.weixin.qq.com/s/7y0-CMAkls16iumNK3mlXg)
- *2025.08*: &nbsp;🎉🎉 We propose [AutoDrive-R²](https://arxiv.org/abs/2509.01944v1), which is now available on ArXiv!
- *2025.06*: &nbsp;🎉🎉 We propose [DVP-MVS++](https://arxiv.org/abs/2506.13215), which is now available on ArXiv!
- *2025.05*: &nbsp;🎉🎉 Our work [SED-MVS](https://ieeexplore.ieee.org/document/11016951) has been ***Accepted*** by ***TCSVT 2025***.
- *2024.12*: &nbsp;🎉🎉 We propose [SED-MVS](https://arxiv.org/abs/2503.13721), which is now available on ArXiv!
- *2024.12*: &nbsp;🎉🎉 Our work [DVP-MVS](https://ojs.aaai.org/index.php/AAAI/article/view/33056) has been ***Accepted*** by ***AAAI 2025***.
- *2024.12*: &nbsp;🎉🎉 Our work [MSP-MVS](https://ojs.aaai.org/index.php/AAAI/article/view/33057) has been ***Accepted*** by ***AAAI 2025***.
- *2024.08*: &nbsp;🎉🎉 We propose [DVP-MVS](https://arxiv.org/abs/2412.11578), which is now available on ArXiv!
- *2024.08*: &nbsp;🎉🎉 We propose [MSP-MVS](https://arxiv.org/abs/2407.19323), which is now available on ArXiv!
- *2024.05*: &nbsp;🎉🎉 Our work [TSAR-MVS](https://www.sciencedirect.com/science/article/pii/S0031320324003169) has been ***Accepted*** by ***PR 2024***.
- *2024.01*: &nbsp;🎉🎉 We propose [TSAR-MVS](https://arxiv.org/abs/2308.09990), which is now available on ArXiv!
- *2023.12*: &nbsp;🎉🎉 Our work [SD-MVS](https://ojs.aaai.org/index.php/AAAI/article/view/28512) has been ***Accepted*** by ***AAAI 2024***.
- *2023.09*: &nbsp;🎉🎉 We propose [SD-MVS](https://arxiv.org/abs/2401.06385), which is now available on ArXiv!

# 📝 Main Publications 

## Multimodal LLMs Post-Training

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">Preprint</div><img src='images/VideoSTAR.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">
[Video-STAR: Reinforcing Zero-shot Video Understanding with Tools](https://arxiv.org/abs/2510.08480)

**Yuan, Z.**, Qu X., Qian, C., Chen, R., Tang, J., Sun L., Chu X., Zhang D., Wang Y., Cai Y., Li S.

[[Paper]](https://arxiv.org/abs/2510.08480)
</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">Preprint</div><img src='images/AutoDrive-R2.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">
[AutoDrive-R²: Incentivizing Reasoning and Self-Reflection Capacity for VLA Model in Autonomous Driving](https://arxiv.org/abs/2509.01944v1)

**Yuan, Z.**, Tang, J., Luo, J., Chen, R., Qian, C., Sun, L., Cai Y., Zhang D., Li, S

[[Paper]](https://arxiv.org/abs/2509.01944v1)
</div>
</div>

## 3D Vision

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">TCSVT</div><img src='images/DVP-MVS++.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">
[DVP-MVS++: Synergize Depth-Normal-Edge and Harmonized Visibility Prior for Multi-View Stereo](https://arxiv.org/abs/2506.13215)

**Yuan, Z.**, Zhang, D., Li, Z., Qian, C., Chen, J., Chen, Y., Chen K., Mao T., Li Z, Jiang H., Wang, Z

IEEE Transactions on Circuits and Systems for Video Technology (**IEEE TCSVT**) (Under Review), 2025.

[[Paper]](https://arxiv.org/abs/2506.13215)
</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">TCSVT</div><img src='images/SED-MVS.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[SED-MVS: Segmentation-Driven and Edge-Aligned Deformation Multi-View Stereo with Depth Restoration and Occlusion Constraint](https://ieeexplore.ieee.org/document/11016951)

**Yuan, Z**., Yang, Z., Cai, Y., Wu, K., Liu, M., Zhang, D., Jiang H, Li Z., Wang, Z.

IEEE Transactions on Circuits and Systems for Video Technology (**IEEE TCSVT**), 2025.

[[Paper]](https://ieeexplore.ieee.org/document/11016951)
</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">AAAI</div><img src='images/DVP-MVS.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">
[DVP-MVS: Synergize Depth-Edge and Visibility Prior for Multi-View Stereo](https://ojs.aaai.org/index.php/AAAI/article/view/33056)

**Yuan, Z**., Luo, J., Shen, F., Li, Z., Liu, C., Mao, T., Wang, Z.

AAAI Conference on Artificial Intelligence (**AAAI**), 2025.

[[Paper]](https://ojs.aaai.org/index.php/AAAI/article/view/33056)
[[Code]](https://github.com/ZhenlongYuan/DVP-MVS)
</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">AAAI</div><img src='images/MSP-MVS.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">
[MSP-MVS: Multi-granularity segmentation prior guided multi-view stereo](https://ojs.aaai.org/index.php/AAAI/article/view/33057)

**Yuan, Z.**, Liu, C., Shen, F., Li, Z., Luo, J., Mao, T., Wang, Z.

AAAI Conference on Artificial Intelligence (**AAAI**), 2025.

[[Paper]](https://ojs.aaai.org/index.php/AAAI/article/view/33057)
[[Code]](https://github.com/ZhenlongYuan/MSP-MVS)
</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">AAAI</div><img src='images/SD-MVS.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">
[SD-MVS: Segmentation-driven deformation multi-view stereo with spherical refinement and em optimization](https://ojs.aaai.org/index.php/AAAI/article/view/28512)

**Yuan, Z.**, Cao, J., Li, Z., Jiang, H., Wang, Z.

AAAI Conference on Artificial Intelligence (**AAAI**), 2024.

[[Paper]](https://ojs.aaai.org/index.php/AAAI/article/view/28512)
[[Code]](https://github.com/ZhenlongYuan/SD-MVS)
</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">PR</div><img src='images/TSAR-MVS.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">
[TSAR-MVS: Textureless-aware segmentation and correlative refinement guided multi-view stereo](https://www.sciencedirect.com/science/article/pii/S0031320324003169)

**Yuan, Z.**, Cao, J., Wang, Z., Li, Z..

Pattern Recognition (**PR**), 2024.

[[Paper]](https://www.sciencedirect.com/science/article/pii/S0031320324003169)
[[Code]](https://github.com/ZhenlongYuan/TSAR-MVS)
</div>
</div>

# 📖 All Publications
- ``Preprint`` [Video-STAR: Reinforcing Zero-shot Video Understanding with Tools.]() **Z Yuan**, X Qu, C Qian, et al.
- ``Preprint`` [AutoDrive-R2: Incentivizing Reasoning and Self-Reflection Capacity for VLA Model in Autonomous Driving.](https://arxiv.org/pdf/2509.01944) **Z Yuan**, J Tang, J Luo, et al.
- ``Preprint`` [Pure Vision Language Action (VLA) Models: A Comprehensive Survey.](https://arxiv.org/pdf/2509.19012) D Zhang, J Sun, C Hu, X Wu, **Z Yuan**, et al.
- ``Preprint`` [AT-Drive: Exploiting Adversarial Transfer for End-to-end Autonomous Driving.]() D Zhang, **Z Yuan**, K Huang, et al.
- ``Preprint`` [ADDI: A Simplified E2E Autonomous Driving Model with Distinct Experts and Implicit Interactions.]() D Zhang, **Z Yuan**, Chen Y., et al.
- ``Preprint`` [EMPOWER: Evolutionary Medical Prompt Optimization With Reinforcement Learning.](https://arxiv.org/pdf/2508.17703) Y Chen, Y He, J Yang, D Zhang, **Z Yuan**, et al. 
- ``Preprint`` [DVP-MVS++: Synergize Depth-Normal-Edge and Harmonized Visibility Prior for Multi-View Stereo.](https://arxiv.org/pdf/2506.13215) **Z Yuan**, D Zhang, Z Li, et al.
- ``NIPS 2025`` [InstructHOI: Context-Aware Instruction for Multi-Modal Reasoning in Human-Object Interaction Detection.]() J Luo, W Ren , Q Zheng, Y Zhang, **Z Yuan**, et al.
- ``IEEE TCSVT 2025`` [Learning multi-view stereo with geometry-aware prior.](https://ieeexplore.ieee.org/abstract/document/11029471) K Chen, **Z Yuan**, H Xiao, T Mao, et al. 
- ``HCII 2025`` [MR-IntelliAssist: A World Cognition Agent Enabling Adaptive Human-AI Symbiosis in Industry 4.0.](https://link.springer.com/chapter/10.1007/978-3-031-93429-2_11), C Liu, **Z Yuan**, Y Wang, Y Yin, et al. 
- ``IEEE TCSVT 2025`` [SED-MVS: Segmentation-Driven and Edge-Aligned Deformation Multi-View Stereo with Depth Restoration and Occlusion Constraint.](https://arxiv.org/pdf/2503.13721), **Z Yuan**, Z Yang, Y Cai, et al. 
- ``AAAI 2025`` [Dual-level precision edges guided multi-view stereo with accurate planarization.](https://ojs.aaai.org/index.php/AAAI/article/view/32208/34363), K Chen, **Z Yuan**, T Mao, et al. 
- ``AAAI 2025`` [Mapexpert: Online hd map construction with simple and efficient sparse map element expert.](https://ojs.aaai.org/index.php/AAAI/article/download/33616/35771), D Zhang, D Chen, P Zhi, Y Chen, **Z Yuan**, et al. 
- ``AAAI 2025`` [DVP-MVS: Synergize depth-edge and visibility prior for multi-view stereo.](https://ojs.aaai.org/index.php/AAAI/article/view/33056/35211), **Z Yuan**, J Luo, F Shen, et al. 
- ``AAAI 2025`` [MSP-MVS: Multi-granularity segmentation prior guided multi-view stereo.](https://ojs.aaai.org/index.php/AAAI/article/download/33057/35212), **Z Yuan**, C Liu, F Shen, et al. 
- ``Preprint`` [Light4gs: Lightweight compact 4d gaussian splatting generation via context model.](https://arxiv.org/pdf/2503.13948?), M Liu, Q Yang, H Huang, W Huang, **Z Yuan**, et al. 
- ``Preprint`` [Adaptive label correction for robust medical image segmentation with noisy labels.](https://arxiv.org/pdf/2503.12218), C Qian, K Han, J Ding, L Liu, C Lyu, **Z Yuan**, et al. 
- ``Preprint`` [Dyncim: Dynamic curriculum for imbalanced multimodal learning.](https://arxiv.org/pdf/2503.06456), C Qian, K Han, J Wang, **Z Yuan**, et al. 
- ``PR 2025`` [Nerf-based polarimetric multi-view stereo.](https://www.sciencedirect.com/science/article/pii/S0031320324007878), J Cao, **Z Yuan**, T Mao, et al. 
- ``PR 2024`` [Tsar-mvs: Textureless-aware segmentation and correlative refinement guided multi-view stereo.](https://arxiv.org/pdf/2308.09990), **Z Yuan**, J Cao, Z Wang, et al. 
- ``AAAI 2024`` [Sd-mvs: Segmentation-driven deformation multi-view stereo with spherical refinement and em optimization.](https://ojs.aaai.org/index.php/AAAI/article/view/28512/28998), **Z Yuan**, J Cao, Z Li, et al.

# 🏆 Awards and Service
- *2024.12* Lenovo Enterprise Scholarship (Top 3%)
- *2025.10* ICT National Scholarships (Top 5%)
- Conference Reviewers: NeurIPS, ICML, ICLR, CVPR, ICCV, ECCV, AAAI
- Journal Reviewers: IJCV, TIP, TMM, TNNLS, TCSVT, PR
